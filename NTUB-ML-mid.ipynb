{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/big-five-personality-test/6.csv\n",
      "data/big-five-personality-test/5.csv\n",
      "data/big-five-personality-test/4.csv\n",
      "data/big-five-personality-test/1.csv\n",
      "data/big-five-personality-test/3.csv\n",
      "data/big-five-personality-test/2.csv\n",
      "data/big-five-personality-test/OCEAN_60000.csv\n"
     ]
    }
   ],
   "source": [
    "data_dir = 'data'\n",
    "\n",
    "if os.path.isdir(data_dir):\n",
    "    for dirname, _, filenames in os.walk(data_dir):\n",
    "        for filename in filenames:\n",
    "            print(os.path.join(dirname, filename))\n",
    "else:\n",
    "    print('Please checkout to include-data branch.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Handle Big Five Personality Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading: data/big-five-personality-test/6.csv, Total: 15342\n",
      "Total: 15342\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>EXT1</th>\n",
       "      <th>EXT2</th>\n",
       "      <th>EXT3</th>\n",
       "      <th>EXT4</th>\n",
       "      <th>EXT5</th>\n",
       "      <th>EXT6</th>\n",
       "      <th>EXT7</th>\n",
       "      <th>EXT8</th>\n",
       "      <th>EXT9</th>\n",
       "      <th>EXT10</th>\n",
       "      <th>...</th>\n",
       "      <th>dateload</th>\n",
       "      <th>screenw</th>\n",
       "      <th>screenh</th>\n",
       "      <th>introelapse</th>\n",
       "      <th>testelapse</th>\n",
       "      <th>endelapse</th>\n",
       "      <th>IPC</th>\n",
       "      <th>country</th>\n",
       "      <th>lat_appx_lots_of_err</th>\n",
       "      <th>long_appx_lots_of_err</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>2018-11-01 10:13:54</td>\n",
       "      <td>414</td>\n",
       "      <td>736</td>\n",
       "      <td>8</td>\n",
       "      <td>253</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>US</td>\n",
       "      <td>38.0</td>\n",
       "      <td>-97.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>2018-11-01 10:13:56</td>\n",
       "      <td>414</td>\n",
       "      <td>896</td>\n",
       "      <td>3</td>\n",
       "      <td>229</td>\n",
       "      <td>2</td>\n",
       "      <td>53</td>\n",
       "      <td>US</td>\n",
       "      <td>32.7776</td>\n",
       "      <td>-83.6802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>2018-11-01 10:14:00</td>\n",
       "      <td>375</td>\n",
       "      <td>812</td>\n",
       "      <td>7</td>\n",
       "      <td>233</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>US</td>\n",
       "      <td>38.0</td>\n",
       "      <td>-97.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>2018-11-01 10:14:03</td>\n",
       "      <td>375</td>\n",
       "      <td>667</td>\n",
       "      <td>3</td>\n",
       "      <td>249</td>\n",
       "      <td>15</td>\n",
       "      <td>53</td>\n",
       "      <td>US</td>\n",
       "      <td>32.7776</td>\n",
       "      <td>-83.6802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>2018-11-01 10:14:04</td>\n",
       "      <td>414</td>\n",
       "      <td>736</td>\n",
       "      <td>4</td>\n",
       "      <td>247</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>US</td>\n",
       "      <td>38.0</td>\n",
       "      <td>-97.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 110 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   EXT1  EXT2  EXT3  EXT4  EXT5  EXT6  EXT7  EXT8  EXT9  EXT10  ...  \\\n",
       "0     2     1     1     4     3     1     4     5     1      5  ...   \n",
       "1     3     3     4     3     3     4     1     2     2      5  ...   \n",
       "2     3     2     3     3     4     2     2     4     3      3  ...   \n",
       "3     3     3     3     2     3     3     3     4     1      3  ...   \n",
       "4     2     2     3     3     3     2     2     4     3      4  ...   \n",
       "\n",
       "              dateload  screenw  screenh  introelapse  testelapse  endelapse  \\\n",
       "0  2018-11-01 10:13:54      414      736            8         253         10   \n",
       "1  2018-11-01 10:13:56      414      896            3         229          2   \n",
       "2  2018-11-01 10:14:00      375      812            7         233          8   \n",
       "3  2018-11-01 10:14:03      375      667            3         249         15   \n",
       "4  2018-11-01 10:14:04      414      736            4         247         14   \n",
       "\n",
       "   IPC  country  lat_appx_lots_of_err  long_appx_lots_of_err  \n",
       "0    1       US                  38.0                  -97.0  \n",
       "1   53       US               32.7776               -83.6802  \n",
       "2    1       US                  38.0                  -97.0  \n",
       "3   53       US               32.7776               -83.6802  \n",
       "4    1       US                  38.0                  -97.0  \n",
       "\n",
       "[5 rows x 110 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_final_dir = 'data/big-five-personality-test'\n",
    "\n",
    "csv_reading = list()\n",
    "is_reduce = True\n",
    "\n",
    "if os.path.isdir(data_final_dir):\n",
    "    for dirname, _, filenames in os.walk(data_final_dir):\n",
    "        for filename in filenames:\n",
    "            if(not is_reduce or filename == '6.csv'):\n",
    "                csv_reading.append(pd.read_csv(os.path.join(dirname, filename), sep='\\t'))\n",
    "                print(f'Reading: {os.path.join(dirname, filename)}, Total: {len(csv_reading[-1])}')\n",
    "else:\n",
    "    print('Please checkout to include-data branch.')\n",
    "\n",
    "data = pd.concat(csv_reading)  \n",
    "\n",
    "print(f'Total: {len(data)}')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reverse value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "positively_keyed = ['EXT1', 'EXT3', 'EXT5', 'EXT7', 'EXT9',\n",
    "                    'EST1', 'EST3', 'EST5', 'EST6', 'EST7', 'EST8', 'EST9', 'EST10',\n",
    "                    'AGR2', 'AGR4', 'AGR6', 'AGR8', 'AGR9', 'AGR10',\n",
    "                    'CSN1', 'CSN3', 'CSN5', 'CSN7', 'CSN9', 'CSN10', \n",
    "                    'OPN1', 'OPN3', 'OPN5', 'OPN7', 'OPN8', 'OPN9', 'OPN10']\n",
    "\n",
    "negatively_keyed = ['EXT2', 'EXT4', 'EXT6', 'EXT8', 'EXT10',\n",
    "                    'EST2', 'EST4',\n",
    "                    'AGR1', 'AGR3', 'AGR5', 'AGR7', \n",
    "                    'CSN2', 'CSN4', 'CSN6', 'CSN8', \n",
    "                    'OPN2', 'OPN4', 'OPN6']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.loc[:, negatively_keyed] = 6 - data.loc[:, negatively_keyed]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Factor aggregation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "EXT = ['EXT' + str(i) for i in range(1,11)]\n",
    "EST = ['EST' + str(i) for i in range(1,11)]\n",
    "AGR = ['AGR' + str(i) for i in range(1,11)]\n",
    "CSN = ['CSN' + str(i) for i in range(1,11)]\n",
    "OPN = ['OPN' + str(i) for i in range(1,11)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['OPN'] = data.loc[:, OPN].mean(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_columns = [] + EXT + EST + AGR + CSN + ['OPN', ]\n",
    "data = data.loc[:, filter_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total: 15342\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>EXT1</th>\n",
       "      <th>EXT2</th>\n",
       "      <th>EXT3</th>\n",
       "      <th>EXT4</th>\n",
       "      <th>EXT5</th>\n",
       "      <th>EXT6</th>\n",
       "      <th>EXT7</th>\n",
       "      <th>EXT8</th>\n",
       "      <th>EXT9</th>\n",
       "      <th>EXT10</th>\n",
       "      <th>...</th>\n",
       "      <th>CSN2</th>\n",
       "      <th>CSN3</th>\n",
       "      <th>CSN4</th>\n",
       "      <th>CSN5</th>\n",
       "      <th>CSN6</th>\n",
       "      <th>CSN7</th>\n",
       "      <th>CSN8</th>\n",
       "      <th>CSN9</th>\n",
       "      <th>CSN10</th>\n",
       "      <th>OPN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>3.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3.9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 41 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   EXT1  EXT2  EXT3  EXT4  EXT5  EXT6  EXT7  EXT8  EXT9  EXT10  ...  CSN2  \\\n",
       "0     2     5     1     2     3     5     4     1     1      1  ...     5   \n",
       "1     3     3     4     3     3     2     1     4     2      1  ...     5   \n",
       "2     3     4     3     3     4     4     2     2     3      3  ...     2   \n",
       "3     3     3     3     4     3     3     3     2     1      3  ...     5   \n",
       "4     2     4     3     3     3     4     2     2     3      2  ...     3   \n",
       "\n",
       "   CSN3  CSN4  CSN5  CSN6  CSN7  CSN8  CSN9  CSN10  OPN  \n",
       "0     5     5     3     5     4     4     4      4  3.3  \n",
       "1     5     4     4     5     5     2     5      5  3.7  \n",
       "2     4     2     3     2     4     2     4      3  3.8  \n",
       "3     5     5     3     5     3     5     3      4  3.6  \n",
       "4     5     4     2     4     4     4     4      4  3.9  \n",
       "\n",
       "[5 rows x 41 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(f'Total: {len(data)}')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EXT1       int64\n",
       "EXT2       int64\n",
       "EXT3       int64\n",
       "EXT4       int64\n",
       "EXT5       int64\n",
       "EXT6       int64\n",
       "EXT7       int64\n",
       "EXT8       int64\n",
       "EXT9       int64\n",
       "EXT10      int64\n",
       "EST1       int64\n",
       "EST2       int64\n",
       "EST3       int64\n",
       "EST4       int64\n",
       "EST5       int64\n",
       "EST6       int64\n",
       "EST7       int64\n",
       "EST8       int64\n",
       "EST9       int64\n",
       "EST10      int64\n",
       "AGR1       int64\n",
       "AGR2       int64\n",
       "AGR3       int64\n",
       "AGR4       int64\n",
       "AGR5       int64\n",
       "AGR6       int64\n",
       "AGR7       int64\n",
       "AGR8       int64\n",
       "AGR9       int64\n",
       "AGR10      int64\n",
       "CSN1       int64\n",
       "CSN2       int64\n",
       "CSN3       int64\n",
       "CSN4       int64\n",
       "CSN5       int64\n",
       "CSN6       int64\n",
       "CSN7       int64\n",
       "CSN8       int64\n",
       "CSN9       int64\n",
       "CSN10      int64\n",
       "OPN      float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_num = data.shape[0]\n",
    "indexes = np.random.permutation(data_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_data: 9205\n",
      "val_data: 3068\n",
      "test_data: 3069\n"
     ]
    }
   ],
   "source": [
    "proportion = [0.98, 0.01, 0.01] if data_num > 1000000 else [0.6, 0.2, 0.2]\n",
    "\n",
    "train_indexes = indexes[:int(data_num *proportion[0])]\n",
    "val_indexes = indexes[int(data_num * proportion[0]):int(data_num * (proportion[0] + proportion[1]))]\n",
    "test_indexes = indexes[int(data_num * (proportion[0] + proportion[1])):]\n",
    "\n",
    "train_data = data.loc[train_indexes]\n",
    "val_data = data.loc[val_indexes]\n",
    "test_data = data.loc[test_indexes]\n",
    "\n",
    "print(f'''train_data: {len(train_data)}\n",
    "val_data: {len(val_data)}\n",
    "test_data: {len(test_data)}''')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_validation_data = pd.concat([train_data, val_data])\n",
    "mean = train_validation_data.mean()\n",
    "std = train_validation_data.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = (train_data - mean) / std\n",
    "val_data = (val_data - mean) / std"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Establish training data in Numpy array format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = np.array(train_data.drop('OPN', axis='columns'))\n",
    "y_train = np.array(train_data['OPN'])\n",
    "x_val = np.array(val_data.drop('OPN', axis='columns'))\n",
    "y_val = np.array(val_data['OPN'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dir = os.path.join('logs', 'models')\n",
    "\n",
    "if not os.path.exists(model_dir):\n",
    "    os.makedirs(model_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialising the ANN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential(name='model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding the input layer and the first hidden layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(layers.Dense(64, kernel_initializer='uniform', activation='relu', input_shape=((len(filter_columns) - 1),)))\n",
    "model.add(layers.Dropout(0.3))\n",
    "model.add(layers.Dense(64, kernel_initializer='uniform', activation='relu'))\n",
    "model.add(layers.Dropout(0.3))\n",
    "model.add(layers.Dense(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compiling the ANN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(keras.optimizers.Adam(0.001),\n",
    "              loss=keras.losses.MeanSquaredError(),\n",
    "              metrics=[keras.metrics.MeanAbsoluteError()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set callback function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_dir = os.path.join('logs', 'model')\n",
    "model_cbk = keras.callbacks.TensorBoard(log_dir=log_dir)\n",
    "model_mckp = keras.callbacks.ModelCheckpoint(os.path.join(model_dir, 'Best-model.h5'), \n",
    "                                             monitor='val_mean_absolute_error', \n",
    "                                             save_best_only=True, \n",
    "                                             mode='min')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 9205 samples, validate on 3068 samples\n",
      "Epoch 1/100\n",
      "9205/9205 [==============================] - 1s 88us/sample - loss: 0.8721 - mean_absolute_error: 0.7488 - val_loss: 0.7473 - val_mean_absolute_error: 0.6904\n",
      "Epoch 2/100\n",
      "9205/9205 [==============================] - 0s 14us/sample - loss: 0.7595 - mean_absolute_error: 0.6924 - val_loss: 0.7312 - val_mean_absolute_error: 0.6867\n",
      "Epoch 3/100\n",
      "9205/9205 [==============================] - 0s 14us/sample - loss: 0.7432 - mean_absolute_error: 0.6849 - val_loss: 0.7271 - val_mean_absolute_error: 0.6809\n",
      "Epoch 4/100\n",
      "9205/9205 [==============================] - 0s 14us/sample - loss: 0.7359 - mean_absolute_error: 0.6825 - val_loss: 0.7261 - val_mean_absolute_error: 0.6794\n",
      "Epoch 5/100\n",
      "9205/9205 [==============================] - 0s 12us/sample - loss: 0.7311 - mean_absolute_error: 0.6788 - val_loss: 0.7252 - val_mean_absolute_error: 0.6829\n",
      "Epoch 6/100\n",
      "9205/9205 [==============================] - 0s 13us/sample - loss: 0.7275 - mean_absolute_error: 0.6785 - val_loss: 0.7214 - val_mean_absolute_error: 0.6775\n",
      "Epoch 7/100\n",
      "9205/9205 [==============================] - 0s 14us/sample - loss: 0.7168 - mean_absolute_error: 0.6738 - val_loss: 0.7180 - val_mean_absolute_error: 0.6733\n",
      "Epoch 8/100\n",
      "9205/9205 [==============================] - 0s 13us/sample - loss: 0.7144 - mean_absolute_error: 0.6707 - val_loss: 0.7217 - val_mean_absolute_error: 0.6759\n",
      "Epoch 9/100\n",
      "9205/9205 [==============================] - 0s 15us/sample - loss: 0.7123 - mean_absolute_error: 0.6702 - val_loss: 0.7153 - val_mean_absolute_error: 0.6704\n",
      "Epoch 10/100\n",
      "9205/9205 [==============================] - 0s 13us/sample - loss: 0.7048 - mean_absolute_error: 0.6658 - val_loss: 0.7174 - val_mean_absolute_error: 0.6777\n",
      "Epoch 11/100\n",
      "9205/9205 [==============================] - 0s 15us/sample - loss: 0.6987 - mean_absolute_error: 0.6645 - val_loss: 0.7176 - val_mean_absolute_error: 0.6739\n",
      "Epoch 12/100\n",
      "9205/9205 [==============================] - 0s 13us/sample - loss: 0.6957 - mean_absolute_error: 0.6618 - val_loss: 0.7184 - val_mean_absolute_error: 0.6744\n",
      "Epoch 13/100\n",
      "9205/9205 [==============================] - 0s 15us/sample - loss: 0.6871 - mean_absolute_error: 0.6589 - val_loss: 0.7145 - val_mean_absolute_error: 0.6704\n",
      "Epoch 14/100\n",
      "9205/9205 [==============================] - 0s 13us/sample - loss: 0.6864 - mean_absolute_error: 0.6600 - val_loss: 0.7143 - val_mean_absolute_error: 0.6730\n",
      "Epoch 15/100\n",
      "9205/9205 [==============================] - 0s 13us/sample - loss: 0.6858 - mean_absolute_error: 0.6572 - val_loss: 0.7149 - val_mean_absolute_error: 0.6750\n",
      "Epoch 16/100\n",
      "9205/9205 [==============================] - 0s 15us/sample - loss: 0.6763 - mean_absolute_error: 0.6525 - val_loss: 0.7146 - val_mean_absolute_error: 0.6734\n",
      "Epoch 17/100\n",
      "9205/9205 [==============================] - 0s 13us/sample - loss: 0.6789 - mean_absolute_error: 0.6554 - val_loss: 0.7184 - val_mean_absolute_error: 0.6729\n",
      "Epoch 18/100\n",
      "9205/9205 [==============================] - 0s 15us/sample - loss: 0.6745 - mean_absolute_error: 0.6527 - val_loss: 0.7172 - val_mean_absolute_error: 0.6764\n",
      "Epoch 19/100\n",
      "9205/9205 [==============================] - 0s 14us/sample - loss: 0.6728 - mean_absolute_error: 0.6521 - val_loss: 0.7173 - val_mean_absolute_error: 0.6750\n",
      "Epoch 20/100\n",
      "9205/9205 [==============================] - 0s 13us/sample - loss: 0.6677 - mean_absolute_error: 0.6480 - val_loss: 0.7151 - val_mean_absolute_error: 0.6740\n",
      "Epoch 21/100\n",
      "9205/9205 [==============================] - 0s 13us/sample - loss: 0.6667 - mean_absolute_error: 0.6487 - val_loss: 0.7190 - val_mean_absolute_error: 0.6752\n",
      "Epoch 22/100\n",
      "9205/9205 [==============================] - 0s 13us/sample - loss: 0.6660 - mean_absolute_error: 0.6481 - val_loss: 0.7197 - val_mean_absolute_error: 0.6739\n",
      "Epoch 23/100\n",
      "9205/9205 [==============================] - 0s 13us/sample - loss: 0.6628 - mean_absolute_error: 0.6481 - val_loss: 0.7179 - val_mean_absolute_error: 0.6723\n",
      "Epoch 24/100\n",
      "9205/9205 [==============================] - 0s 13us/sample - loss: 0.6626 - mean_absolute_error: 0.6476 - val_loss: 0.7202 - val_mean_absolute_error: 0.6744\n",
      "Epoch 25/100\n",
      "9205/9205 [==============================] - 0s 13us/sample - loss: 0.6569 - mean_absolute_error: 0.6438 - val_loss: 0.7178 - val_mean_absolute_error: 0.6731\n",
      "Epoch 26/100\n",
      "9205/9205 [==============================] - 0s 13us/sample - loss: 0.6530 - mean_absolute_error: 0.6417 - val_loss: 0.7231 - val_mean_absolute_error: 0.6764\n",
      "Epoch 27/100\n",
      "9205/9205 [==============================] - 0s 13us/sample - loss: 0.6497 - mean_absolute_error: 0.6397 - val_loss: 0.7220 - val_mean_absolute_error: 0.6750\n",
      "Epoch 28/100\n",
      "9205/9205 [==============================] - 0s 12us/sample - loss: 0.6509 - mean_absolute_error: 0.6415 - val_loss: 0.7242 - val_mean_absolute_error: 0.6781\n",
      "Epoch 29/100\n",
      "9205/9205 [==============================] - 0s 12us/sample - loss: 0.6514 - mean_absolute_error: 0.6405 - val_loss: 0.7264 - val_mean_absolute_error: 0.6782\n",
      "Epoch 30/100\n",
      "9205/9205 [==============================] - 0s 12us/sample - loss: 0.6447 - mean_absolute_error: 0.6378 - val_loss: 0.7290 - val_mean_absolute_error: 0.6775\n",
      "Epoch 31/100\n",
      "9205/9205 [==============================] - 0s 12us/sample - loss: 0.6432 - mean_absolute_error: 0.6387 - val_loss: 0.7235 - val_mean_absolute_error: 0.6760\n",
      "Epoch 32/100\n",
      "9205/9205 [==============================] - 0s 11us/sample - loss: 0.6416 - mean_absolute_error: 0.6364 - val_loss: 0.7247 - val_mean_absolute_error: 0.6737\n",
      "Epoch 33/100\n",
      "9205/9205 [==============================] - 0s 12us/sample - loss: 0.6390 - mean_absolute_error: 0.6361 - val_loss: 0.7290 - val_mean_absolute_error: 0.6785\n",
      "Epoch 34/100\n",
      "9205/9205 [==============================] - 0s 12us/sample - loss: 0.6348 - mean_absolute_error: 0.6326 - val_loss: 0.7300 - val_mean_absolute_error: 0.6810\n",
      "Epoch 35/100\n",
      "9205/9205 [==============================] - 0s 12us/sample - loss: 0.6369 - mean_absolute_error: 0.6373 - val_loss: 0.7300 - val_mean_absolute_error: 0.6784\n",
      "Epoch 36/100\n",
      "9205/9205 [==============================] - 0s 12us/sample - loss: 0.6352 - mean_absolute_error: 0.6336 - val_loss: 0.7303 - val_mean_absolute_error: 0.6745\n",
      "Epoch 37/100\n",
      "9205/9205 [==============================] - 0s 12us/sample - loss: 0.6299 - mean_absolute_error: 0.6321 - val_loss: 0.7321 - val_mean_absolute_error: 0.6774\n",
      "Epoch 38/100\n",
      "9205/9205 [==============================] - 0s 12us/sample - loss: 0.6319 - mean_absolute_error: 0.6350 - val_loss: 0.7318 - val_mean_absolute_error: 0.6786\n",
      "Epoch 39/100\n",
      "9205/9205 [==============================] - 0s 12us/sample - loss: 0.6324 - mean_absolute_error: 0.6318 - val_loss: 0.7331 - val_mean_absolute_error: 0.6806\n",
      "Epoch 40/100\n",
      "9205/9205 [==============================] - 0s 13us/sample - loss: 0.6303 - mean_absolute_error: 0.6318 - val_loss: 0.7379 - val_mean_absolute_error: 0.6841\n",
      "Epoch 41/100\n",
      "9205/9205 [==============================] - 0s 12us/sample - loss: 0.6269 - mean_absolute_error: 0.6311 - val_loss: 0.7357 - val_mean_absolute_error: 0.6769\n",
      "Epoch 42/100\n",
      "9205/9205 [==============================] - 0s 12us/sample - loss: 0.6289 - mean_absolute_error: 0.6316 - val_loss: 0.7354 - val_mean_absolute_error: 0.6785\n",
      "Epoch 43/100\n",
      "9205/9205 [==============================] - 0s 12us/sample - loss: 0.6299 - mean_absolute_error: 0.6337 - val_loss: 0.7316 - val_mean_absolute_error: 0.6794\n",
      "Epoch 44/100\n",
      "9205/9205 [==============================] - 0s 12us/sample - loss: 0.6225 - mean_absolute_error: 0.6272 - val_loss: 0.7305 - val_mean_absolute_error: 0.6776\n",
      "Epoch 45/100\n",
      "9205/9205 [==============================] - 0s 12us/sample - loss: 0.6195 - mean_absolute_error: 0.6256 - val_loss: 0.7350 - val_mean_absolute_error: 0.6783\n",
      "Epoch 46/100\n",
      "9205/9205 [==============================] - 0s 13us/sample - loss: 0.6224 - mean_absolute_error: 0.6294 - val_loss: 0.7367 - val_mean_absolute_error: 0.6789\n",
      "Epoch 47/100\n",
      "9205/9205 [==============================] - 0s 12us/sample - loss: 0.6195 - mean_absolute_error: 0.6269 - val_loss: 0.7410 - val_mean_absolute_error: 0.6816\n",
      "Epoch 48/100\n",
      "9205/9205 [==============================] - 0s 12us/sample - loss: 0.6131 - mean_absolute_error: 0.6232 - val_loss: 0.7414 - val_mean_absolute_error: 0.6803\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49/100\n",
      "9205/9205 [==============================] - 0s 12us/sample - loss: 0.6121 - mean_absolute_error: 0.6258 - val_loss: 0.7378 - val_mean_absolute_error: 0.6803\n",
      "Epoch 50/100\n",
      "9205/9205 [==============================] - 0s 11us/sample - loss: 0.6160 - mean_absolute_error: 0.6239 - val_loss: 0.7457 - val_mean_absolute_error: 0.6864\n",
      "Epoch 51/100\n",
      "9205/9205 [==============================] - 0s 12us/sample - loss: 0.6165 - mean_absolute_error: 0.6257 - val_loss: 0.7410 - val_mean_absolute_error: 0.6826\n",
      "Epoch 52/100\n",
      "9205/9205 [==============================] - 0s 12us/sample - loss: 0.6123 - mean_absolute_error: 0.6236 - val_loss: 0.7361 - val_mean_absolute_error: 0.6809\n",
      "Epoch 53/100\n",
      "9205/9205 [==============================] - 0s 12us/sample - loss: 0.6119 - mean_absolute_error: 0.6217 - val_loss: 0.7476 - val_mean_absolute_error: 0.6884\n",
      "Epoch 54/100\n",
      "9205/9205 [==============================] - 0s 12us/sample - loss: 0.6102 - mean_absolute_error: 0.6219 - val_loss: 0.7370 - val_mean_absolute_error: 0.6801\n",
      "Epoch 55/100\n",
      "9205/9205 [==============================] - 0s 11us/sample - loss: 0.6081 - mean_absolute_error: 0.6200 - val_loss: 0.7374 - val_mean_absolute_error: 0.6792\n",
      "Epoch 56/100\n",
      "9205/9205 [==============================] - 0s 12us/sample - loss: 0.6080 - mean_absolute_error: 0.6199 - val_loss: 0.7429 - val_mean_absolute_error: 0.6830\n",
      "Epoch 57/100\n",
      "9205/9205 [==============================] - 0s 12us/sample - loss: 0.6081 - mean_absolute_error: 0.6212 - val_loss: 0.7390 - val_mean_absolute_error: 0.6831\n",
      "Epoch 58/100\n",
      "9205/9205 [==============================] - 0s 12us/sample - loss: 0.6085 - mean_absolute_error: 0.6199 - val_loss: 0.7406 - val_mean_absolute_error: 0.6820\n",
      "Epoch 59/100\n",
      "9205/9205 [==============================] - 0s 12us/sample - loss: 0.6082 - mean_absolute_error: 0.6210 - val_loss: 0.7406 - val_mean_absolute_error: 0.6826\n",
      "Epoch 60/100\n",
      "9205/9205 [==============================] - 0s 12us/sample - loss: 0.6074 - mean_absolute_error: 0.6209 - val_loss: 0.7436 - val_mean_absolute_error: 0.6796\n",
      "Epoch 61/100\n",
      "9205/9205 [==============================] - 0s 12us/sample - loss: 0.6036 - mean_absolute_error: 0.6176 - val_loss: 0.7429 - val_mean_absolute_error: 0.6850\n",
      "Epoch 62/100\n",
      "9205/9205 [==============================] - 0s 12us/sample - loss: 0.6113 - mean_absolute_error: 0.6226 - val_loss: 0.7396 - val_mean_absolute_error: 0.6827\n",
      "Epoch 63/100\n",
      "9205/9205 [==============================] - 0s 12us/sample - loss: 0.5997 - mean_absolute_error: 0.6172 - val_loss: 0.7461 - val_mean_absolute_error: 0.6857\n",
      "Epoch 64/100\n",
      "9205/9205 [==============================] - 0s 12us/sample - loss: 0.6016 - mean_absolute_error: 0.6191 - val_loss: 0.7438 - val_mean_absolute_error: 0.6812\n",
      "Epoch 65/100\n",
      "9205/9205 [==============================] - 0s 12us/sample - loss: 0.6013 - mean_absolute_error: 0.6187 - val_loss: 0.7399 - val_mean_absolute_error: 0.6804\n",
      "Epoch 66/100\n",
      "9205/9205 [==============================] - 0s 12us/sample - loss: 0.6013 - mean_absolute_error: 0.6172 - val_loss: 0.7378 - val_mean_absolute_error: 0.6804\n",
      "Epoch 67/100\n",
      "9205/9205 [==============================] - 0s 12us/sample - loss: 0.5944 - mean_absolute_error: 0.6122 - val_loss: 0.7462 - val_mean_absolute_error: 0.6870\n",
      "Epoch 68/100\n",
      "9205/9205 [==============================] - 0s 12us/sample - loss: 0.5980 - mean_absolute_error: 0.6166 - val_loss: 0.7462 - val_mean_absolute_error: 0.6838\n",
      "Epoch 69/100\n",
      "9205/9205 [==============================] - 0s 12us/sample - loss: 0.5954 - mean_absolute_error: 0.6155 - val_loss: 0.7424 - val_mean_absolute_error: 0.6829\n",
      "Epoch 70/100\n",
      "9205/9205 [==============================] - 0s 12us/sample - loss: 0.5990 - mean_absolute_error: 0.6175 - val_loss: 0.7475 - val_mean_absolute_error: 0.6851\n",
      "Epoch 71/100\n",
      "9205/9205 [==============================] - 0s 12us/sample - loss: 0.6020 - mean_absolute_error: 0.6175 - val_loss: 0.7430 - val_mean_absolute_error: 0.6848\n",
      "Epoch 72/100\n",
      "9205/9205 [==============================] - 0s 12us/sample - loss: 0.5937 - mean_absolute_error: 0.6142 - val_loss: 0.7448 - val_mean_absolute_error: 0.6854\n",
      "Epoch 73/100\n",
      "9205/9205 [==============================] - 0s 12us/sample - loss: 0.5819 - mean_absolute_error: 0.6077 - val_loss: 0.7424 - val_mean_absolute_error: 0.6819\n",
      "Epoch 74/100\n",
      "9205/9205 [==============================] - 0s 12us/sample - loss: 0.5933 - mean_absolute_error: 0.6141 - val_loss: 0.7484 - val_mean_absolute_error: 0.6872\n",
      "Epoch 75/100\n",
      "9205/9205 [==============================] - 0s 12us/sample - loss: 0.5944 - mean_absolute_error: 0.6129 - val_loss: 0.7452 - val_mean_absolute_error: 0.6847\n",
      "Epoch 76/100\n",
      "9205/9205 [==============================] - 0s 12us/sample - loss: 0.5935 - mean_absolute_error: 0.6140 - val_loss: 0.7418 - val_mean_absolute_error: 0.6831\n",
      "Epoch 77/100\n",
      "9205/9205 [==============================] - 0s 11us/sample - loss: 0.5819 - mean_absolute_error: 0.6073 - val_loss: 0.7477 - val_mean_absolute_error: 0.6846\n",
      "Epoch 78/100\n",
      "9205/9205 [==============================] - 0s 12us/sample - loss: 0.5770 - mean_absolute_error: 0.6072 - val_loss: 0.7500 - val_mean_absolute_error: 0.6846\n",
      "Epoch 79/100\n",
      "9205/9205 [==============================] - 0s 12us/sample - loss: 0.5828 - mean_absolute_error: 0.6086 - val_loss: 0.7519 - val_mean_absolute_error: 0.6882\n",
      "Epoch 80/100\n",
      "9205/9205 [==============================] - 0s 13us/sample - loss: 0.5831 - mean_absolute_error: 0.6068 - val_loss: 0.7524 - val_mean_absolute_error: 0.6891\n",
      "Epoch 81/100\n",
      "9205/9205 [==============================] - 0s 12us/sample - loss: 0.5795 - mean_absolute_error: 0.6077 - val_loss: 0.7504 - val_mean_absolute_error: 0.6876\n",
      "Epoch 82/100\n",
      "9205/9205 [==============================] - 0s 12us/sample - loss: 0.5848 - mean_absolute_error: 0.6091 - val_loss: 0.7524 - val_mean_absolute_error: 0.6884\n",
      "Epoch 83/100\n",
      "9205/9205 [==============================] - 0s 12us/sample - loss: 0.5927 - mean_absolute_error: 0.6150 - val_loss: 0.7496 - val_mean_absolute_error: 0.6869\n",
      "Epoch 84/100\n",
      "9205/9205 [==============================] - 0s 13us/sample - loss: 0.5842 - mean_absolute_error: 0.6089 - val_loss: 0.7472 - val_mean_absolute_error: 0.6870\n",
      "Epoch 85/100\n",
      "9205/9205 [==============================] - 0s 12us/sample - loss: 0.5840 - mean_absolute_error: 0.6087 - val_loss: 0.7486 - val_mean_absolute_error: 0.6876\n",
      "Epoch 86/100\n",
      "9205/9205 [==============================] - 0s 12us/sample - loss: 0.5826 - mean_absolute_error: 0.6092 - val_loss: 0.7521 - val_mean_absolute_error: 0.6875\n",
      "Epoch 87/100\n",
      "9205/9205 [==============================] - 0s 12us/sample - loss: 0.5785 - mean_absolute_error: 0.6047 - val_loss: 0.7444 - val_mean_absolute_error: 0.6839\n",
      "Epoch 88/100\n",
      "9205/9205 [==============================] - 0s 12us/sample - loss: 0.5765 - mean_absolute_error: 0.6058 - val_loss: 0.7515 - val_mean_absolute_error: 0.6859\n",
      "Epoch 89/100\n",
      "9205/9205 [==============================] - 0s 12us/sample - loss: 0.5745 - mean_absolute_error: 0.6034 - val_loss: 0.7473 - val_mean_absolute_error: 0.6857\n",
      "Epoch 90/100\n",
      "9205/9205 [==============================] - 0s 12us/sample - loss: 0.5737 - mean_absolute_error: 0.6033 - val_loss: 0.7492 - val_mean_absolute_error: 0.6854\n",
      "Epoch 91/100\n",
      "9205/9205 [==============================] - 0s 12us/sample - loss: 0.5816 - mean_absolute_error: 0.6064 - val_loss: 0.7431 - val_mean_absolute_error: 0.6836\n",
      "Epoch 92/100\n",
      "9205/9205 [==============================] - 0s 12us/sample - loss: 0.5785 - mean_absolute_error: 0.6057 - val_loss: 0.7434 - val_mean_absolute_error: 0.6862\n",
      "Epoch 93/100\n",
      "9205/9205 [==============================] - 0s 12us/sample - loss: 0.5794 - mean_absolute_error: 0.6052 - val_loss: 0.7536 - val_mean_absolute_error: 0.6914\n",
      "Epoch 94/100\n",
      "9205/9205 [==============================] - 0s 12us/sample - loss: 0.5783 - mean_absolute_error: 0.6064 - val_loss: 0.7505 - val_mean_absolute_error: 0.6856\n",
      "Epoch 95/100\n",
      "9205/9205 [==============================] - 0s 11us/sample - loss: 0.5744 - mean_absolute_error: 0.6026 - val_loss: 0.7501 - val_mean_absolute_error: 0.6855\n",
      "Epoch 96/100\n",
      "9205/9205 [==============================] - 0s 12us/sample - loss: 0.5748 - mean_absolute_error: 0.6060 - val_loss: 0.7578 - val_mean_absolute_error: 0.6897\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 97/100\n",
      "9205/9205 [==============================] - 0s 12us/sample - loss: 0.5748 - mean_absolute_error: 0.6020 - val_loss: 0.7521 - val_mean_absolute_error: 0.6859\n",
      "Epoch 98/100\n",
      "9205/9205 [==============================] - 0s 12us/sample - loss: 0.5737 - mean_absolute_error: 0.6037 - val_loss: 0.7573 - val_mean_absolute_error: 0.6883\n",
      "Epoch 99/100\n",
      "9205/9205 [==============================] - 0s 12us/sample - loss: 0.5762 - mean_absolute_error: 0.6066 - val_loss: 0.7536 - val_mean_absolute_error: 0.6902\n",
      "Epoch 100/100\n",
      "9205/9205 [==============================] - 0s 12us/sample - loss: 0.5661 - mean_absolute_error: 0.5979 - val_loss: 0.7544 - val_mean_absolute_error: 0.6859\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x_train, y_train,\n",
    "               batch_size=150,\n",
    "               epochs=100,\n",
    "               validation_data=(x_val, y_val),\n",
    "               callbacks=[model_cbk, model_mckp])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Verify the effectiveness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.load_model(os.path.join(model_dir, 'Best-model.h5'))\n",
    "\n",
    "y_test = np.array(test_data['OPN'])\n",
    "test_data = (test_data - mean) / std\n",
    "\n",
    "x_test = np.array(test_data.drop('OPN', axis='columns'))\n",
    "y_pred = model.predict(x_test)\n",
    "y_pred = np.reshape(y_pred * std['OPN'] + mean['OPN'], y_test.shape)\n",
    "model_percentage_error = np.nanmean(np.abs(y_test - y_pred)) / np.nanmean(y_test) * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results of training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Percentage Error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: 11.44%\n"
     ]
    }
   ],
   "source": [
    "print(\"Model: {:.2f}%\".format(model_percentage_error))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## acc - loss curve diagram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x144c4a978>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['mean_absolute_error'], label='train acc')\n",
    "plt.plot(history.history['loss'], label='train loss')\n",
    "plt.plot(history.history['val_mean_absolute_error'], label='val acc')\n",
    "plt.plot(history.history['val_loss'], label='val loss')\n",
    "plt.ylim(0.02, 0.2)\n",
    "plt.title('Mean square error')\n",
    "plt.ylabel('acc - loss')\n",
    "plt.xlabel('epochs')\n",
    "plt.legend(loc='upper right')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6.8 64-bit ('.venv': virtualenv)",
   "language": "python",
   "name": "python36864bitvenvvirtualenvacaff34b38d84bbdb38c32a940f37472"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
